
# default basic settings for UCAgent
lang: "zh"

# init commands to run at the start of the agent
init_cmds: []

# backend
backend:
  key_name: "langchain"  # options: langchain, claude_code, opencode, copilot_cli, etc.
  langchain:
    clss: ucagent.abackend.langchain.UCAgentLangChainBackend
  claude_code:
    clss: ucagent.abackend.UCAgentCmdLineBackend
    args:
      cli_cmd_new: "claude --dangerously-skip-permissions -p < {MSG_FILE}"
      cli_cmd_ctx: "claude --dangerously-skip-permissions -c -p < {MSG_FILE}"
      pre_bash_cmd:
        - "mkdir -p {CWD}/.claude/"
        - "cp ~/.claude/.mcp.json {CWD}/.mcp.json" # Add a project-scoped server claude mcp add --scope project ...., then backup the config to ~/.claude/.mcp.json
        - "sed -i \"s/5000\/mcp/{PORT}\/mcp/\" {CWD}/.mcp.json" # modify the mcp port (5000) to the configured port
  opencode:
    clss: ucagent.abackend.UCAgentCmdLineBackend
    args:
      cli_cmd_new: "opencode run < {MSG_FILE}"
      cli_cmd_ctx: "opencode run -c < {MSG_FILE}"
    pre_bash_cmd:
      - "cp ~/.config/opencode/opencode.json {CWD}/opencode.json" # You need to setup opencode config first
      - "sed -i \"s/5000\/mcp/{PORT}\/mcp/\" {CWD}/opencode.json" # modify the server port (5000) to the configured port
  copilot_cli:
    clss: ucagent.abackend.UCAgentCmdLineBackend
    args:
      cli_cmd_new: "copilot --allow-all-tools -p < {MSG_FILE}"
      cli_cmd_ctx: "copilot --allow-all-tools --continue -p < {MSG_FILE}"
    pre_bash_cmd:
      - "mkdir -p {CWD}/.copilot/"
      - "cp ~/.copilot/mcp-config.json {CWD}/.copilot/mcp-config.json"
      - "sed -i \"s/5000\/mcp/{PORT}\/mcp/\" {CWD}/.copilot/mcp-config.json" # modify the mcp port (5000) to the configured port

mcp_server:
  host: 127.0.0.1
  port: 5000

# Model support: openai, anthropic, google_genai
model_type: openai

openai:
  model_name: "$(OPENAI_MODEL: <your_chat_model_name>)"
  openai_api_key: "$(OPENAI_API_KEY: [your_api_key])"
  openai_api_base: "$(OPENAI_API_BASE: http://<your_chat_model_url>/v1)"
  model_kwargs:
    stop: ["."]

# export ANTHROPIC_API_KEY="your-api-key"
anthropic:
  model: "$(ANTHROPIC_MODEL: claude-3-7-sonnet-20250219)"

# export GOOGLE_GENAI_API_KEY="your-api-key"
google_genai:
  model: "$(GOOGLE_GENAI_MODEL: gemini-2.5-pro)"

embed:
  model_name: "$(EMBED_MODEL: <your_embedding_model_name>)"
  openai_api_key: "$(EMBED_OPENAI_API_KEY: [your_api_key])"
  openai_api_base: "$(EMBED_OPENAI_API_BASE: http://<your_embedding_model_url>/v1)"
  dims: 1024

langfuse:
  enable: $(ENABLE_LANGFUSE, false)
  public_key: $(LANGFUSE_PUBLIC_KEY, <YOUR_LANGFUSE_PUBLIC_KEY>)
  secret_key: $(LANGFUSE_SECRET_KEY, <YOUR_LANGFUSE_SECRET_KEY>)
  base_url: $(LANGFUSE_URL, http://localhost:3000)

# This is the setting for conversation summary
# Adjust the max_tokens and max_summary_tokens according to your needs and model capabilities
# Reference doc: https://langchain-ai.lang.chat/langmem/reference/short_term/#langmem.short_term.SummarizationNode
# if use_uc_mode is false (summarization mode):
#   Param: max_tokens, suggested 50% of the model's context length
# if use_uc_mode is true (unity chip summarization and trim mode):
#   Param: max_tokens is not used
#   Param: max_summary_tokens, suggested 10% of the model's context length
conversation_summary:
  max_tokens: 128000    # default 50k tokens for 128k context model
  max_summary_tokens: 1024
  max_keep_msgs: 200   # max messages to keep in memory, older messages will be removed (not the messages to LLM)
  use_uc_mode: true    # default use uc mode to manage conversation history
  tail_keep_msgs: 10   # when use_uc_mode is true, keep the last N messages to the LLM no matter what

# Context upgrade switches


context_upgrade:
  enable_all: &context_upgrade_all false
  enable_data_collection: *context_upgrade_all # when true, log stage token usage and write run summary to res.csv
  enable_rerank: *context_upgrade_all         # when true, apply lightweight re-ranking on semantic search results
  enable_structured_summary: *context_upgrade_all # when true, use structured schema-oriented summaries instead of free-form
  enable_hierarchical_summary: *context_upgrade_all # when true, add Batch/Stage summaries (no long-term storage)
  enable_compact_test_output: *context_upgrade_all # when true, compact pytest stdout/stderr before adding to context
  enable_long_term_memory: *context_upgrade_all # when true, persist long-term memory to disk (jsonl)
  enable_long_term_memory_embed: *context_upgrade_all # when true, use embeddings for long-term memory search
  enable_failure_aware_context: *context_upgrade_all # when true, label failure vs non-failure context in prompt
  

rate_limiter:
  enabled: false
  # The following settings are used when rate_limiter.enabled is true
  requests_per_second: 10    # default 10 req/s
  check_every_n_seconds: 0.1 # default 0.1s, wake up every 100 ms to check whether allowed to make a request
  max_bucket_size: 1         # default 1, controls the maximum burst size

template: unity_test

un_write_dirs:
  - "{DUT}"
  - "Guide_Doc"
write_dirs:
  - "{OUT}"

tools:
  RunTestCases:
    test_dir: "{OUT}/tests"
  ignore_tools: ["WorkDiff", "WorkCommit"] # List of tool names to ignore
  selected_tools: []     # List of tool names to enable, if empty, all tools are enabled except those in ignore_tools

# Tool call timeout
call_time_out: 300  # seconds

# TUI layout settings
tui:
  task_width: 84
  console_height: 13
  status_height: 7


hooks:
  continue: >
    You have not completed all the tasks yet. Please continue. Use the `Check` and `Complete` tools to determine whether you have finished the current stage's tasks.
    Please verify the results of the `Check` and `Complete` tool calls, and adjust your work based on the feedback until all `Check` and `Complete` calls are passed.
    If a timeout error occurs, please increase the timeout parameter and retry, or use the RunTestCases tool to identify any stuck test cases and fix them.

  cagent_init: >
    Please get your role information and basic guidance through tool `RoleInfo`, and then complete the task.
    Please make sure to use the tool `ReadTextFile` to read the file, so that UCAgent can know which files you have read.

  quit: "/quit"

  exit: "/exit"
